---
permalink: /
title: "Martin BÃ¼chner"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi everybody, I'm Martin and currently a PhD student at the [ELLIS Robot Learning Lab](https://rl.uni-freiburg.de/) at the University of Freiburg supervised by Prof. Abhinav Valada. I enjoy conducting research in the fields of autonomous robotics and 3D scene understanding with a focus on developing actionable robotic maps via abstraction using 3D scene graphs. In particular, I am interested in combining these representations with natural language to enable robots to follow instructions for navigation and mobile manipulation.

Before starting my PhD, I have had the pleasure of studying Robotics and AI at the [Technical University of Munich (TUM)](https://tum.de) and spent a wonderful couple of months in Seoul at Seoul National University (SNU). Before that, I started my academic journey as a Bachelor's student in Mechanical Engineering at [Karlsruhe Institute of Technology (KIT)](https://kit.edu/)

## Selected Publications

<img style="float: right" src="images/artipoint.png" height="200px" width="180px" border="3px"> [Articulated Object Estimation in the Wild](https://artipoint.cs.uni-freiburg.de/)
Abdelrhman Werby\*, Martin BÃ¼chner\*, Adrian RÃ¶fer\*, Chenguang Huang, Wolfram Burgard, Abhinav Valada <br>
Best Paper Award Runner-Up: RSS'25 Workshop on Egocentric Perception and Action for Robot Learning. <br>
<i>Conference on Robot Learning (CoRL), 2025.</i>
<br>


<img style="float: right" src="images/openlex3d.png" height="200px" width="180px" border="3px"> [OpenLex3D: A Tiered Evaluation Benchmark for Open-Vocabulary 3D Scene Representations](https://openlex3d.github.io)<br>
Christina Kassab\*, Sacha Morin\*, Martin BÃ¼chner\*, MatÃ­as Mattamala, Kumaraditya Gupta, Abhinav Valada, Liam Paull, Maurice Fallon <br>
<i>ICRA 2025 Workshop on Safely Leveraging Vision-Language Foundation Models in Robotics</i>
<i>arXiv preprint arXiv:2503.19764, 2025.</i>
<br>

<img style="float: right" src="images/more.png" height="200px" width="180px" border="3px"> [MORE: Mobile Manipulation Rearrangement Through Grounded Language Reasoning](https://more-model.cs.uni-freiburg.de/)<br>
Mohammad Mohammadi\*, Daniel Honerkamp\*, Martin BÃ¼chner\*, Matteo Cassinelli\*, Tim Welschehold, Fabien Despinoy, Igor Gilitschenski, Abhinav Valada <br> 
<i>RSS Workshop on Mobile Manipulation: Emerging Opportunities & Contemporary Challenges, 2025.</i><br>
<i>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2025. </i>
<br>

<img style="float: right" src="images/loopgnn.png" height="200px" width="180px" border="3px"> [Visual Loop Closure Detection Through Deep Graph Consensus](https://loopgnn.cs.uni-freiburg.de/)<br>
Martin BÃ¼chner, Liza Dahiya, Simon Dorer, Vipul Ramtekkar, Kenji Nishimiya, Daniele Cattaneo, Abhinav Valada <br>
<i>IEEE/RSJ International Conference on Robots and Intelligent Systems (IROS), 2025.</i>
<br>

<img style="float: right" src="images/curb-osg.png" height="200px" width="180px" border="3px"> [Collaborative Dynamic 3D Scene Graphs for Open-Vocabulary Scene Understanding](https://ov-curb.cs.uni-freiburg.de/)<br>
Tim Steinke\*, Martin BÃ¼chner\*, Niclas VÃ¶disch\*, Abhinav Valada <br>
<i>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2025.</i>
<br>

<img style="float: right" src="images/hovsg.png" height="200px" width="180px" border="3px"> [Hierarchical Open-Vocabulary 3D Scene Graphs for Language-Grounded Robot Navigation](https://hovsg.github.io/)<br>
Abdelrhman Werby\*, Chenguang Huang\*, Martin BÃ¼chner\*, Abhinav Valada, Wolfram Burgard <br>
<i>ICRA 2024 Workshop on Vision and Language Models for Navigation and Manipulation (VLMNM).</i> <br>
<i>Robotics: Science and Systems (RSS), 2024. </i>
<br>

<img style="float: right" src="images/moma-llm.png" height="200px" width="180px" border="3px"> [Language-Grounded Dynamic Scene Graphs for Interactive Object Search with Mobile Manipulation](https://moma-llm.cs.uni-freiburg.de/)<br>
Daniel Honerkamp\*, Martin BÃ¼chner\*, Fabian Despinoy, Tim Welschehold, Abhinav Valada <br>
<i>Spotlight Talk: RSS 2024 Workshop on Semantic Reasoning and Goal Understanding in Robotics (SemRob). </i><br>
<i>Spotlight Talk: ICRA 2024 Workshop on Vision and Language Models for Navigation and Manipulation (VLMNM). </i><br>
<i>IEEE Robotics and Automation Letters (RA-L), 2024. </i>
<br>

<img style="float: right" src="images/curb-sg.png" height="200px" width="180px" border="3px"> [Collaborative Dynamic 3D Scene Graphs for Automated Driving](https://curb.cs.uni-freiburg.de/)<br>
Elias Greve\*, Martin BÃ¼chner\*, Niclas VÃ¶disch\*, Wolfram Burgard, Abhinav Valada <br>
<i>IEEE International Conference on Robotics and Automation (ICRA), 2024 ðŸ‡¯ðŸ‡µ.</i>
<br>

<img style="float: right" src="images/learning2drive.png" height="200px" width="180px" border="3px"> [Efficient Learning of Urban Driving Policies Using Bird's-Eye-View Representations](https://learning2drive.cs.uni-freiburg.de/)<br>
Raphael Trumpp\*, Martin BÃ¼chner\*, Abhinav Valada, Marco Caccamo <br> 
<i>IEEE Intelligent Transportation Systems Conference (ITSC), 2023.</i>
<br>

<img style="float: right" src="images/lanegnn.png" height="200px" width="180px" border="3px"> [Learning and Aggregating Lane Graphs for Urban Automated Driving](http://urbanlanegraph.cs.uni-freiburg.de)<br> 
Martin BÃ¼chner\*, Jannik ZÃ¼rn\*, Ion-George Todoran, Abhinav Valada, Wolfram Burgard <br>
<i>IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR), 2023.</i>
<br>

<img style="float: right" src="images/batch3dmot.png" height="200px" width="180px" border="3px"> [3D Multi-Object Tracking Using Graph Neural Networks with Cross-Edge Modality Attention](https://batch3dmot.cs.uni-freiburg.de/)<br>
Martin BÃ¼chner, Abhinav Valada <br>
<i>IEEE Robotics and Automation Letters (RA-L), 2022 + IROS.</i>